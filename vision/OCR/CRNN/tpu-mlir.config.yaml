---

name: vision_OCR_CRNN_tpu-mlir
gops: [1.46]
shapes:
  - [1, 1, 32, 100]

model: $(home)/crnn.onnx

mlir_transform:
  model_transform.py
    --model_name $(name)
    --model_def $(model)
    --test_input $(root)/dataset/samples/ocr_img.jpg
    --input_shapes [$(shape_param)]
    --resize_dims 32,100
    --mean 127.5
    --scale 0.007843
    --pixel_format gray
    --debug_cmd use_pil_resize
    --test_result $(name)_top_outputs.npz
    --mlir $(workdir)/transformed.mlir

# mlir_calibration:
#   run_calibration.py $(workdir)/transformed.mlir
#     --dataset $(root)/dataset/IIIT5K/caliset
#     --input_num 100
#     --excepts
#     -o $(home)/cali_table

deploy:
  - model_deploy.py  --mlir $(workdir)/transformed.mlir
      --quantize F32
      --chip $(target)
      --test_input $(workdir)/$(name)_in_f32.npz
      --test_reference $(name)_top_outputs.npz
      --tolerance 0.99,0.99
      --model $(workdir)/$(name)_$(target)_f32.bmodel
  - model_deploy.py --mlir $(workdir)/transformed.mlir
      --quantize INT8
      --calibration_table $(home)/cali_table
      --quant_input
      --quant_output
      --chip $(target)
      --test_input $(workdir)/$(name)_in_f32.npz
      --test_reference $(name)_top_outputs.npz
      --tolerance 0.95,0.72
      --model $(workdir)/$(name)_$(target)_int8_sym.bmodel

BM1684X:
  +deploy:
    - model_deploy.py  --mlir $(workdir)/transformed.mlir
        --quantize F32
        --chip $(target)
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.99,0.99
        --model $(workdir)/$(name)_$(target)_f32.bmodel
    - model_deploy.py  --mlir $(workdir)/transformed.mlir
        --quantize F16
        --chip $(target)
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.95,0.85
        --model $(workdir)/$(name)_$(target)_f16.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize BF16
        --chip $(target)
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.95,0.85
        --model $(workdir)/$(name)_$(target)_bf16.bmodel
    - model_deploy.py --mlir $(workdir)/transformed.mlir
        --quantize INT8
        --calibration_table $(home)/cali_table
        --quant_input
        --quant_output
        --chip $(target)
        --test_input $(workdir)/$(name)_in_f32.npz
        --test_reference $(name)_top_outputs.npz
        --tolerance 0.95,0.72
        --model $(workdir)/$(name)_$(target)_int8_sym.bmodel
